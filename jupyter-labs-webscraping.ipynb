{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Falcon 9 and Falcon Heavy Launches Records from Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **40** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be performing web scraping to collect Falcon 9 historical launch records from a Wikipedia page titled `List of Falcon 9 and Falcon Heavy launches`\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/Falcon9_rocket_family.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falcon 9 first stage will land successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several examples of an unsuccessful landing are shown here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, the launch records are stored in a HTML table shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/falcon9-launches-wiki.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Objectives\n",
    "Web scrap Falcon 9 launch records with `BeautifulSoup`: \n",
    "- Extract a Falcon 9 launch records HTML table from Wikipedia\n",
    "- Parse the table and convert it into a Pandas data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import required packages for this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will provide some helper functions for you to process web scraped HTML table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the data and time from the HTML  table cell\n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the booster version from the HTML  table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])\n",
    "    return out\n",
    "\n",
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=[i for i in table_cells.strings][0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass\n",
    "\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter the digit and empty names\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the lab tasks consistent, you will be asked to scrape the data from a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on\n",
    "`9th June 2021`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, request the HTML page from the above URL and get a `response` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Request the Falcon9 Launch Wiki page from its URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's perform an HTTP GET method to request the Falcon9 Launch HTML page, as an HTTP response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Page retrieved.\n"
     ]
    }
   ],
   "source": [
    "# use requests.get() method with the provided static_url\n",
    "import requests\n",
    "# Use requests.get() to request the HTML page\n",
    "response = requests.get(static_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Success! Page retrieved.\")\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")\n",
    "# assign the response to a object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BeautifulSoup` object from the HTML `response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeautifulSoup object created successfully\n",
      "<title>List of Falcon 9 and Falcon Heavy launches - Wikipedia</title>\n"
     ]
    }
   ],
   "source": [
    "# Use BeautifulSoup() to create a BeautifulSoup object from a response text content\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Static URL\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "\n",
    "# Get the HTML content\n",
    "response = requests.get(static_url)\n",
    "\n",
    "# Check for successful response\n",
    "if response.status_code == 200:\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')  # Use 'html.parser' or 'lxml'\n",
    "    print(\"BeautifulSoup object created successfully\")\n",
    "    # You can now use soup to parse the HTML\n",
    "    # For example, to print the title of the page:\n",
    "    print(soup.title)\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the page title to verify if the `BeautifulSoup` object was created properly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Falcon 9 and Falcon Heavy launches - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Use soup.title attribute\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Static URL\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "\n",
    "# Get the HTML content\n",
    "response = requests.get(static_url)\n",
    "\n",
    "# Check for successful response\n",
    "if response.status_code == 200:\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Print the page title\n",
    "    print(soup.title.string)  # Access the string within the title tag\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_falcon9 = launch_df[launch_df['BoosterVersion'] == 'Falcon 9']\n",
    "num_falcon9_launches = len(data_falcon9)\n",
    "print(f\"Number of Falcon 9 launches: {num_falcon9_launches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Extract all column/variable names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to collect all relevant column names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all tables on the wiki page first. If you need to refresh your memory about `BeautifulSoup`, please check the external reference link towards the end of this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables found: 26\n"
     ]
    }
   ],
   "source": [
    "# Use the find_all function in the BeautifulSoup object, with element type `table`\n",
    "# Assign the result to a list called `html_tables`\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "response = requests.get(static_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    html_tables = soup.find_all('table')\n",
    "\n",
    "    # Print the number of tables found (for verification)\n",
    "    print(f\"Number of tables found: {len(html_tables)}\")\n",
    "\n",
    "    #Optional: print the first table to see what it contains\n",
    "    #print(html_tables[0])\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the third table is our target table contains the actual launch records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should able to see the columns names embedded in the table header elements `<th>` as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<tr>\n",
    "<th scope=\"col\">Flight No.\n",
    "</th>\n",
    "<th scope=\"col\">Date and<br/>time (<a href=\"/wiki/Coordinated_Universal_Time\" title=\"Coordinated Universal Time\">UTC</a>)\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/List_of_Falcon_9_first-stage_boosters\" title=\"List of Falcon 9 first-stage boosters\">Version,<br/>Booster</a> <sup class=\"reference\" id=\"cite_ref-booster_11-0\"><a href=\"#cite_note-booster-11\">[b]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Launch site\n",
    "</th>\n",
    "<th scope=\"col\">Payload<sup class=\"reference\" id=\"cite_ref-Dragon_12-0\"><a href=\"#cite_note-Dragon-12\">[c]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Payload mass\n",
    "</th>\n",
    "<th scope=\"col\">Orbit\n",
    "</th>\n",
    "<th scope=\"col\">Customer\n",
    "</th>\n",
    "<th scope=\"col\">Launch<br/>outcome\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/Falcon_9_first-stage_landing_tests\" title=\"Falcon 9 first-stage landing tests\">Booster<br/>landing</a>\n",
    "</th></tr>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to iterate through the `<th>` elements and apply the provided `extract_column_from_header()` to extract column name one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['Flight No.', 'Date andtime (UTC)', 'Version,Booster [b]', 'Launch site', 'Payload[c]', 'Payload mass', 'Orbit', 'Customer', 'Launchoutcome', 'Boosterlanding', '1', '2', '3', '4', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "column_names = []\n",
    "\n",
    "# Apply find_all() function with `th` element on first_launch_table\n",
    "# Iterate each th element and apply the provided extract_column_from_header() to get a column name\n",
    "# Append the Non-empty column name (`if name is not None and len(name) > 0`) into a list called column_names\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "response = requests.get(static_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    html_tables = soup.find_all('table')\n",
    "\n",
    "    # Select the third table (index 2)\n",
    "    first_launch_table = html_tables[2]\n",
    "\n",
    "    # Extract column names\n",
    "    column_names = []\n",
    "    for th in first_launch_table.find_all('th'):\n",
    "        name = th.text.strip()  # Extract text and remove leading/trailing spaces\n",
    "        if name and len(name) > 0:  # Check if the name is not empty\n",
    "            column_names.append(name)\n",
    "\n",
    "    print(\"Column Names:\", column_names)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extracted column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight No.', 'Date andtime (UTC)', 'Version,Booster [b]', 'Launch site', 'Payload[c]', 'Payload mass', 'Orbit', 'Customer', 'Launchoutcome', 'Boosterlanding', '1', '2', '3', '4', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Create a data frame by parsing the launch HTML tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty dictionary with keys from the extracted column names in the previous task. Later, this dictionary will be converted into a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "response = requests.get(static_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    html_tables = soup.find_all('table')\n",
    "    first_launch_table = html_tables[2]\n",
    "\n",
    "    column_names = []\n",
    "    for th in first_launch_table.find_all('th'):\n",
    "        name = th.text.strip()\n",
    "        if name:\n",
    "            column_names.append(name)\n",
    "\n",
    "    launch_dict = dict.fromkeys(column_names)\n",
    "\n",
    "    # Remove irrelevant column (handle potential KeyError)\n",
    "    try:\n",
    "        del launch_dict['Date and time ( )']\n",
    "    except KeyError:\n",
    "        print(\"Key 'Date and time ( )' not found in column names.\")\n",
    "\n",
    "    # Initialize dictionary values as empty lists\n",
    "    launch_dict['Flight No.'] = []\n",
    "    launch_dict['Launch site'] = []\n",
    "    launch_dict['Payload'] = []\n",
    "    launch_dict['Payload mass'] = []\n",
    "    launch_dict['Orbit'] = []\n",
    "    launch_dict['Customer'] = []\n",
    "    launch_dict['Launch outcome'] = []\n",
    "    launch_dict['Version Booster'] = []\n",
    "    launch_dict['Booster landing'] = []\n",
    "    launch_dict['Date'] = []\n",
    "    launch_dict['Time'] = []\n",
    "    print(launch_dict)\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to fill up the `launch_dict` with launch records extracted from table rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, HTML tables in Wiki pages are likely to contain unexpected annotations and other types of noises, such as reference links `B0004.1[8]`, missing values `N/A [e]`, inconsistent formatting, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the parsing process, we have provided an incomplete code snippet below to help you to fill up the `launch_dict`. Please complete the following code snippet with TODOs or you can choose to write your own logic to parse all launch tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 'Date and time ( )' not found in column names.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def date_time(element):\n",
    "    \"\"\"Extracts date and time from a table cell element.\n",
    "\n",
    "    Args:\n",
    "        element (bs4.element.Tag): The table cell element containing date and time.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the extracted date and time strings.\n",
    "    \"\"\"\n",
    "    return [el.strip(',') for el in element.text.split(' ')]  # Split, strip commas, return as list\n",
    "\n",
    "def booster_version(element):\n",
    "    \"\"\"Extracts booster version from a table cell element.\n",
    "\n",
    "    Args:\n",
    "        element (bs4.element.Tag): The table cell element containing booster version.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted booster version string, or None if not found.\n",
    "    \"\"\"\n",
    "    if element.a:  # Check if there's an anchor tag\n",
    "        return element.a.string  # Extract text from anchor tag\n",
    "    else:\n",
    "        return None  # No version found\n",
    "\n",
    "def get_mass(element):\n",
    "    \"\"\"Extracts payload mass from a table cell element.\n",
    "\n",
    "    Args:\n",
    "        element (bs4.element.Tag): The table cell element containing payload mass.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted payload mass string, or None if not found.\n",
    "    \"\"\"\n",
    "    mass_text = element.text.strip()  # Extract and strip text\n",
    "    if mass_text:\n",
    "        return mass_text.replace('kg', '')  # Remove unit if it exists\n",
    "    else:\n",
    "        return None  # No mass found\n",
    "\n",
    "def landing_status(element):\n",
    "    \"\"\"Extracts launch outcome from a table cell element.\n",
    "\n",
    "    Args:\n",
    "        element (bs4.element.Tag): The table cell element containing launch outcome.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted launch outcome string, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to find a specific class (may change in the future)\n",
    "        landing_text = element.find('div', class_='mw-collapsible-text').text.strip()\n",
    "        return landing_text\n",
    "    except AttributeError:\n",
    "        return None  # No landing status found\n",
    "\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "response = requests.get(static_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    html_tables = soup.find_all('table', \"wikitable plainrowheaders collapsible\")\n",
    "    launch_dict = dict.fromkeys(column_names)\n",
    "\n",
    "    # Remove irrelevant column (handle potential KeyError)\n",
    "    try:\n",
    "        del launch_dict['Date and time ( )']\n",
    "    except KeyError:\n",
    "        print(\"Key 'Date and time ( )' not found in column names.\")\n",
    "\n",
    "    # Initialize dictionary values as empty lists\n",
    "    launch_dict['Flight No.'] = []\n",
    "    launch_dict['Launch site'] = []\n",
    "    launch_dict['Payload'] = []\n",
    "    launch_dict['Payload mass'] = []\n",
    "    launch_dict['Orbit'] = []\n",
    "    launch_dict['Customer'] = []\n",
    "    launch_dict['Launch outcome'] = []\n",
    "    launch_dict['Version Booster'] = []\n",
    "    launch_dict['Booster landing'] = []\n",
    "    launch_dict['Date'] = []\n",
    "    launch_dict['Time'] = []\n",
    "\n",
    "    extracted_row = 0\n",
    "    for table_number, table in enumerate(html_tables):\n",
    "        for rows in table.find_all(\"tr\"):\n",
    "            if rows.th:\n",
    "                if rows.th.string:\n",
    "                    flight_number = rows.th.string.strip()\n",
    "                    flag = flight_number.isdigit()\n",
    "            else:\n",
    "                flag = False\n",
    "\n",
    "            row = rows.find_all('td')\n",
    "            if flag:\n",
    "                extracted_row += 1\n",
    "\n",
    "                # Flight Number\n",
    "                launch_dict['Flight No.'].append(flight_number)\n",
    "\n",
    "                # Date and Time\n",
    "                datetime_list = date_time(row[0])\n",
    "                launch_dict['Date'].append(datetime_list[0])\n",
    "                launch_dict['Time'].append(datetime_list[1])\n",
    "\n",
    "                # Booster Version\n",
    "                bv = booster_version(row[1])\n",
    "                launch_dict['Version Booster'].append(bv)\n",
    "\n",
    "                # Launch Site\n",
    "                launch_site = row[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have fill in the parsed launch record values into `launch_dict`, you can create a dataframe from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def date_time(element):\n",
    "    return [el.strip(',') for el in element.text.split(' ')]\n",
    "\n",
    "def booster_version(element):\n",
    "    if element.a:\n",
    "        return element.a.string\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_mass(element):\n",
    "    mass_text = element.text.strip()\n",
    "    if mass_text:\n",
    "        return mass_text.replace('kg', '').replace(',', '')  # Remove commas as well\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def landing_status(element):\n",
    "    try:\n",
    "        landing_text = element.find('div', class_='mw-collapsible-text').text.strip()\n",
    "        return landing_text\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "response = requests.get(static_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    html_tables = soup.find_all('table', \"wikitable plainrowheaders collapsible\")\n",
    "\n",
    "    column_names = []\n",
    "    for th in html_tables[2].find_all('th'): #Extract from the third table only\n",
    "        name = th.text.strip()\n",
    "        if name:\n",
    "            column_names.append(name)\n",
    "    launch_dict = dict.fromkeys(column_names)\n",
    "    try:\n",
    "        del launch_dict['Date and time ( )']\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    launch_dict['Flight No.'] = []\n",
    "    launch_dict['Launch site'] = []\n",
    "    launch_dict['Payload'] = []\n",
    "    launch_dict['Payload mass'] = []\n",
    "    launch_dict['Orbit'] = []\n",
    "    launch_dict['Customer'] = []\n",
    "    launch_dict['Launch outcome'] = []\n",
    "    launch_dict['Version Booster'] = []\n",
    "    launch_dict['Booster landing'] = []\n",
    "    launch_dict['Date'] = []\n",
    "    launch_dict['Time'] = []\n",
    "\n",
    "    extracted_row = 0\n",
    "    for table_number, table in enumerate(html_tables):\n",
    "        if table_number == 2: #Extract from the third table only\n",
    "            for rows in table.find_all(\"tr\"):\n",
    "                if rows.th:\n",
    "                    if rows.th.string:\n",
    "                        flight_number = rows.th.string.strip()\n",
    "                        if flight_number.isdigit():\n",
    "                            flag = True\n",
    "                        else:\n",
    "                            flag = False\n",
    "                    else:\n",
    "                        flag = False\n",
    "                else:\n",
    "                    flag = False\n",
    "\n",
    "                row = rows.find_all('td')\n",
    "                if flag:\n",
    "                    extracted_row += 1\n",
    "                    try: #Added try except blocks to handle potential index errors\n",
    "                        launch_dict['Flight No.'].append(flight_number)\n",
    "                        datetime_list = date_time(row[0])\n",
    "                        launch_dict['Date'].append(datetime_list[0])\n",
    "                        launch_dict['Time'].append(datetime_list[1])\n",
    "                        bv = booster_version(row[1])\n",
    "                        launch_dict['Version Booster'].append(bv)\n",
    "                        launch_dict['Launch site'].append(row[2].a.string)\n",
    "                        launch_dict['Payload'].append(row[3].a.string)\n",
    "                        launch_dict['Payload mass'].append(get_mass(row[4]))\n",
    "                        launch_dict['Orbit'].append(row[5].a.string)\n",
    "                        launch_dict['Customer'].append(row[6].a.string)\n",
    "                        launch_dict['Launch outcome'].append(list(row[7].strings)[0])\n",
    "                        launch_dict['Booster landing'].append(landing_status(row[8]))\n",
    "                    except IndexError:\n",
    "                        print(f\"IndexError at row {extracted_row}. Skipping row.\")\n",
    "\n",
    "    df = pd.DataFrame({key: pd.Series(value) for key, value in launch_dict.items()})\n",
    "    print(df.head())\n",
    "    print(df.info())\n",
    "else:\n",
    "    print(f\"Error: Failed to retrieve page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame({ key:pd.Series(value) for key, value in launch_dict.items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export it to a <b>CSV</b> for the next section, but to make the answers consistent and in case you have difficulties finishing this lab. \n",
    "\n",
    "Following labs will be using a provided dataset to make each lab independent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>df.to_csv('spacex_web_scraped.csv', index=False)</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/yan-luo-96288783/\">Yan Luo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/nayefaboutayoun/\">Nayef Abou Tayoun</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n",
    "| ----------------- | ------- | ---------- | ----------------------- |\n",
    "| 2021-06-09        | 1.0     | Yan Luo    | Tasks updates           |\n",
    "| 2020-11-10        | 1.0     | Nayef      | Created the initial version |\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "64f1b0aac408997185c47caba18730e0028b75e7934a0e5bf0ae73c5cb7ba677"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
